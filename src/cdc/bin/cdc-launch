#!/bin/bash
#
# Launch sets the following environment variables for use in docker-compose
#
#   CDC_APP_PATH: the application directory of the compose app
#   CDC_DBUS_PATH: the path to the unix socket used by dbus or dbus-proxy
#   CDC_DBUS_SYSTEM_PATH: the path to the unix socket used by dbus or dbus-proxy
#   CDC_PWD: the path of the working dir on the host system where the app was launched
#            (useful for console scripts that run on files in that working directory, *if* it is also mounted inside the container)

set -e

# Fix formatting of CDC_DEBUG so it always is a positive integer
if [ -z "$CDC_DEBUG" ]; then
    CDC_DEBUG=0
elif ! [[ "$CDC_DEBUG" =~ ^[0-9]+$ ]]; then
    CDC_DEBUG=1
fi

export CDC_PWD="$(pwd -P)"
SCRIPTPATH="$(dirname -- "$(realpath -- "$0")")"
CDC_CONFIG_DIR="${XDG_CONFIG_HOME:-$HOME/.config}/cdc"
CDC_DATA_DIR="${XDG_DATA_HOME:-$HOME/.local/share}/cdc"
LAUNCHPATH="$(cd -- "$(dirname "$0")" >/dev/null 2>&1 ; pwd -P)"
TOOLPATH="$(dirname -- "${SCRIPTPATH}")/tools"

PODMAN_COMPOSE_UP_ARGS=()
PODMAN_COMPOSE_EXEC_ARGS=()
PODMAN_COMPOSE_EXEC_POST_ARGS=()
PODMAN_UP_ARGS=()
PODMAN_EXEC_ARGS=()

if [ -z "$(readlink "$0")" ]; then
    # Non-symlink invokation
    if [ "$1" == "-h" -o "$1" == "--help" ]; then
	echo "Usage: $0 <launcher> [args ...]"
	echo
	echo "Run the app via the requested launcher"
	exit 0
    fi
    LAUNCHER="$1"
    shift 1
else
    # Symlink invokation
    LAUNCHER=$(basename "$0")
    if [ "$(basename "$LAUNCHPATH")" != "setup" ]; then
	cd "$LAUNCHPATH"
    else
	cd "$(dirname "$LAUNCHPATH")"
    fi
fi

APP="$(basename -- "$(pwd -P)")"

if ! yq -r '."x-application"' compose.yaml > /dev/null 2>&1 || [ "$(yq -r '."x-application"' compose.yaml 2>/dev/null)" == "null" ]; then
    echo "=== Error dump ==="
    yq -r '."x-application"' compose.yaml && true
    echo "=================="

    echo "Something is wrong with the compose.yaml file (see error dump above)."
    exit 1
fi

export CDC_APP_PATH="$(pwd -P)"
export CDC_USER="$USER"

PODMAN_CONFIG=$(podman-compose -f compose.yaml -f override.yaml config)
if [ "$(yq -r ".\"x-launchers\".\"$LAUNCHER\"" <<< "$PODMAN_CONFIG")" == "null" ]; then
    if [ "$CDC_LAUNCH_SILENT" != "1" ]; then
        echo "The requested launcher ${LAUNCHER} does not seem to be defined."
    fi
    exit 1
fi

TYPE=$(yq -r ".\"x-launchers\".\"$LAUNCHER\".type" <<< "$PODMAN_CONFIG")
if [ -z "$TYPE" -o "$TYPE" == "null" ]; then
    TYPE=normal
fi

SERVICE=$(yq -r ".\"x-launchers\".\"$LAUNCHER\".service" <<< "$PODMAN_CONFIG")
if [ "$TYPE" != "tray" -a -z "$SERVICE" -o "$SERVICE" == "null" ]; then
    echo "The launcher stanza for ${LAUNCHER} is missing 'service'."
    exit 1
fi

CONFIG_FILE=()
if [ -e override.yaml ]; then
    CONFIG_FILE+=("-f" "override.yaml")
fi

ENV_FILE=()
if [ -e .env ]; then
    ENV_FILE+=("--env-file" ".env")
fi

# Launchers built explicity to run in the console use a different hostname to avoid confusion;
# launchers that run in the background need to use the hosts hostname to not confuse e.g., X11 about which host they run on
if yq -e ".\"x-launchers\".\"$LAUNCHER\".console == true" > /dev/null <<< "$PODMAN_CONFIG"; then
    export CDC_HOSTNAME="cdc_${APP}_${LAUNCHER}"
else
    export CDC_HOSTNAME="$(hostname)"
fi
PODMAN_UP_ARGS+=( "--hostname" "$CDC_HOSTNAME" )

ADJUSTMENT_FILE=$(mktemp /tmp/desktop-containers-override.XXXXXX.yaml)
trap "rm -f '$ADJUSTMENT_FILE'" EXIT
cat <<EOF > "$ADJUSTMENT_FILE"
version: "3.8"
EOF

# Prepare sensible values for DBUS_SESSION_BUS_ADDRESS and DBUS_SYSTEM_BUS_ADDRESS in case they are not set
# and figure out the paths to the respective socket.
if [ -z "$DBUS_SESSION_BUS_ADDRESS" ]; then
    export DBUS_SESSION_BUS_ADDRESS="unix:path=/run/user/${UID}/bus"
fi
export CDC_DBUS_PATH="${DBUS_SESSION_BUS_ADDRESS/unix:path=}"

if [ -z "$DBUS_SYSTEM_BUS_ADDRESS" ]; then
    export DBUS_SYSTEM_BUS_ADDRESS="unix:path=/run/dbus/system_bus_socket"
fi
export CDC_DBUS_SYSTEM_PATH="${DBUS_SESSION_BUS_ADDRESS/unix:path=}"

function GET_FEATURE_ARG() {
    FEATURE="$1"
    if [ -n "$2" ]; then
	ARGNAME=".\"$2\""
    else
	ARGNAME=""
    fi
    ARG=$(yq -r ".services.\"$SERVICE\".\"x-features\"[]? | select(type==\"object\") | select(has(\"$FEATURE\"))| .\"$FEATURE\"${ARGNAME}" <<< "$PODMAN_CONFIG")
    if [ "$ARG" == "null" ]; then
       ARG=""
    fi
    echo "$ARG"
}

ADJUSTMENT_ENVS=()
ADJUSTMENT_DEVS=()
ADJUSTMENT_VOLS=()
ADJUSTMENT_CAPS=()
OVERRIDE_ALLOW_READ="no"

ADJUSTMENT_ENVS+=( "XDG_RUNTIME_DIR: /run/user/${UID}" )

# If the image starts with "cdc-" we auto-mount a number of path components from the expanded filesystem instead
IMAGE="$(yq -r ".services.\"$SERVICE\".\"image\"" <<< "$PODMAN_CONFIG")"
if [ "${IMAGE#cdc-}" != "${IMAGE}" ]; then
    IMGDIR="$CDC_DATA_DIR/image-${IMAGE#cdc-}"
    for ROOTMOUNT in bin boot etc home sbin srv usr var; do
	ADJUSTMENT_VOLS+=( "$IMGDIR/rootfs/$ROOTMOUNT:/$ROOTMOUNT:ro" )
    done
    ADJUSTMENT_VOLS+=( "${IMGDIR}/opt:/opt:ro" )
fi

# Always mount the cdc tools at /cdc, and /opt
ADJUSTMENT_VOLS+=( "${TOOLPATH}/container:/cdc:ro" "/etc/timezone:/etc/timezone:ro" )

if [ "$(yq -r ".\"x-launchers\".\"$LAUNCHER\".script" <<< "$PODMAN_CONFIG")" != "null" ]; then
    LAUNCH_SCRIPT="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".script | recurse(.[]? // empty) | select(type != \"array\")" <<< "$PODMAN_CONFIG")"
else
    LAUNCH_SCRIPT=""
fi
if [ "$TYPE" != "tray" -a -z "$LAUNCH_SCRIPT" -o "$LAUNCH_SCRIPT" == "null" ]; then
    echo "No launch command defined for $APP $LAUNCHER"
    exit 1
fi
if [ "$CDC_DEBUG" -ge "2" ]; then
  echo "==== LAUNCH SCRIPT ===="
  printf "%s\n" "$LAUNCH_SCRIPT"
  echo "======================="
fi

#export CDC_INIT_SCRIPT=""
#if [ "${#INIT_COMMANDS[@]}" != "0" ]; then
#    CDC_INIT_SCRIPT="$(printf '%s;\n' "${INIT_COMMANDS[@]}")"
#fi
#
#if [ "$(echo "$PODMAN_CONFIG" | yq -r ".services.\"$LAUNCHER\".\"x-application\".\"init-script\"" <<< "$PODMAN_CONFIG")" != "null" ]; then
#    CDC_INIT_SCRIPT="${CDC_INIT_SCRIPT}$(echo "$PODMAN_CONFIG" | yq -r ".services.\"$LAUNCHER\".\"x-application\".\"init-script\" | recurse(.[]? // empty) | select(type != \"array\")")"
#fi
#
#export CDC_CALL_ARGS=""
#for ARG in "$@"; do
#    CDC_CALL_ARGS="${CDC_CALL_ARGS} $(echo "$ARG"|base64)"
#done

# If compose file specifically uses x-app-init, we need to force CAP_SETUID + CAP_SETGID to start as root and then drop to user
#if [ -n "$CDC_INIT_SCRIPT" ]; then
#    ADJUSTMENT_CAPS+=( "CAP_SETUID" "CAP_SETGID" )
#fi

if [ "$(yq ".services.\"$SERVICE\".\"x-features\"" <<< "$PODMAN_CONFIG")" != "null" ]; then
    # Loop over all featues that are strings or objects
    for FEATURE in $(yq -r ".services.\"$SERVICE\".\"x-features\"[]? | select(type==\"string\")" <<< "$PODMAN_CONFIG") $(yq -r ".services.\"$SERVICE\".\"x-features\"[]? | select(type==\"object\") | keys[]?" <<< "$PODMAN_CONFIG"); do

	echo "Enabling feature: $FEATURE"

	# Enable host-tmp-mount ONLY if using Wayland, used for appindicator workarounds
	if [ "$FEATURE" = "wayland-mount-host-tmp" ]; then
	    if [ -n "$WAYLAND_DISPLAY" ]; then
		FEATURE="mount-host-tmp"
	    fi
	fi

	if [ "$FEATURE" = "mount-host-tmp" ]; then
	    ADJUSTMENT_VOLS+=( "/tmp/cdc/$APP:/tmp/cdc/$APP:rw" )
	    ADJUSTMENT_ENVS+=( "CDC_HOSTTMP_PATH: /tmp/cdc/$APP" )
	fi

	if [ "$FEATURE" = "wayland-fallback-x11" ]; then
	    if [ -n "$WAYLAND_DISPLAY" ]; then
		FEATURE="wayland"
	    else
		FEATURE="x11"
	    fi
	fi

	if [ "$FEATURE" = "video" ]; then
	    # TODO: Hotplug system not yet working
	    #if [ ! -e /dev/container-hotplug ]; then
	    #    echo "WARNING: system appear to be missing the udev setup to support hotplugging of video devices."
	    #    echo "Only video devices available at startup will be supported."
		for DEV in /dev/video*; do
		    if [ -c "$DEV" ]; then
	    		ADJUSTMENT_DEVS+=( "$DEV" )			
	    		#ADJUSTMENT_DEVS+=( "$DEV:/dev/video/${DEV#/dev/}" )
	    	    fi
		done
	    #else
	    #	ADJUSTMENT_DEVS+=( "/dev/container-hotplug/video:/dev/container-hotplug/video" )
	    #	PODMAN_UP_ARGS+=( "--group-add" "video ")
	    #	#VIDEO_GID="$(getent group video | awk -F: '{print $3}')"
	    #	#PODMAN_UP_ARGS+=( "--gidmap=$VIDEO_GID:$VIDEO_GID:1" )
	    #fi
	    #INIT_COMMANDS+=( "echo -n {0..9} | xargs -d ' '  -i ln -s /dev/video/video{} /dev/video{}" )
            #ADJUSTMENT_CAPS+=( "CAP_SETUID" "CAP_SETGID" )

	elif [ "$FEATURE" = "wayland" ]; then
	    ADJUSTMENT_ENVS+=( "WAYLAND_DISPLAY: ${WAYLAND_DISPLAY}" )
	    ADJUSTMENT_VOLS+=( "${XDG_RUNTIME_DIR}/${WAYLAND_DISPLAY}:/run/user/${UID}/${WAYLAND_DISPLAY}:ro" )
	    ADJUSTMENT_ENVS+=( "CDC_OZONE_FLAGS: --ozone-platform=wayland --enable-features=WaylandWindowDecorations,UseOzonePlatform")
            ADJUSTMENT_ENVS+=( "QT_QPA_PLATFORM: wayland")
            ADJUSTMENT_ENVS+=( "XDG_SESSION_TYPE: wayland")

	elif [ "$FEATURE" = "x11" ]; then
	    ADJUSTMENT_ENVS+=( "DISPLAY: \"${DISPLAY}\"" "XAUTHORITY: \"${XAUTHORITY}\"" )
	    ADJUSTMENT_VOLS+=( "/tmp/.X11-unix:/tmp/.X11-unix:rw" "${XAUTHORITY}:${XAUTHORITY}:rw" )
	    ADJUSTMENT_ENVS+=( "CDC_OZONE_FLAGS: --ozone-platform=x11")
            ADJUSTMENT_ENVS+=( "XDG_SESSION_TYPE: x11")

        elif [ "$FEATURE" = "gpu_dri" ]; then
            GLXINFO=$(glxinfo || true)
            if grep -q 'direct rendering: Yes' <<< "$GLXINFO" && grep -q 'OpenGL vendor string: NVIDIA' <<< "$GLXINFO"; then
                if [ ! -e /etc/cdi/nvidia.yaml -a ! -e /var/run/cdi/nvidia.yaml ]; then
                    echo "To support 'full-dri', this system needs a CDI configuration from the NVIDIA container toolkit, which is not detected!"
                    echo "Please install the nvidia-container-toolkit (if not already installed) and then generate a configration using this command:"
                    echo "  nvidia-ctk cdi generate | sudo tee cat > /etc/cdi/nvidia.yaml"
                    exit 1
                fi
                PODMAN_UP_ARGS+=( "--device nvidia.com/gpu=all" )
                OVERRIDE_ALLOW_READ="yes"
	    elif [ "0" = "1" ]; then
		# INTEL
		DUMMY=""
	    elif [ "0" = "1" ]; then
		# AMD
		DUMMY=""
	    else
                echo "Warning: gpu_dri feature specified, but no installed gpu accelerator recognized."
		ADJUSTMENT_VOLS+=( "/dev/dri:/dev/dri" )
            fi
	elif [ "$FEATURE" = "gpu_compute" ]; then
	    if command -v nvidia-smi 2>/dev/null; then
		# NVIDIA
                PODMAN_UP_ARGS+=( "--device nvidia.com/gpu=all" )
                OVERRIDE_ALLOW_READ="yes"
	    elif [ "0" = "1" ]; then
		# INTEL
		DUMMY=""
	    elif [ "0" = "1" ]; then
		# AMD
		DUMMY=""
            else
                echo "Warning: gpu_compute feature specified, but no installed gpu accelerator recognized."
	    fi
	elif [ "$FEATURE" = "sound" ]; then
	    ADJUSTMENT_VOLS+=( "${XDG_RUNTIME_DIR}/pipewire-0:/run/user/${UID}/pipewire-0:rw" )
	    ADJUSTMENT_DEVS+=( "/dev/snd:/dev/snd" )

	elif [ "$FEATURE" == "dbus-proxy" ]; then
	    DBUS_PROXY=1
	    DBUS_PROXY_ARGS=( $(GET_FEATURE_ARG dbus-proxy) )
	    CDC_DBUS_PATH="$XDG_RUNTIME_DIR/bus-proxy-$APP-$LAUNCHER"
            ADJUSTMENT_VOLS+=( "${CDC_DBUS_PATH}:/run/user/${UID}/bus:rw" )
	    ADJUSTMENT_ENVS+=( "DBUS_SESSION_BUS_ADDRESS: \"unix:path=/run/user/${UID}/bus\"" )

	elif [ "$FEATURE" == "dbus-system-proxy" ]; then
	    DBUS_SYSTEM_PROXY=1
	    DBUS_SYSTEM_PROXY_ARGS=( $(GET_FEATURE_ARG dbus-system-proxy) )
	    CDC_DBUS_SYSTEM_PATH="$XDG_RUNTIME_DIR/system-bus-proxy-$APP-$LAUNCHER"
	    ADJUSTMENT_VOLS+=( "${CDC_DBUS_SYSTEM_PATH}:/run/dbus/system_bus_socket:rw" )
	    ADJUSTMENT_ENVS+=( "DBUS_SYSTEM_BUS_ADDRESS: \"unix:path=/run/dbus/system_bus_socket\"" )
	else
            echo "The compose.yaml file specifies an unknown feature: $FEATURE" >&2
            exit 1
        fi
    done
fi

cat <<EOF >> "$ADJUSTMENT_FILE"
services:
  $SERVICE:
    x-dummy:
EOF
if [ -n "$ADJUSTMENT_DEVS" ]; then
  cat <<EOF >> "$ADJUSTMENT_FILE"
    devices:
EOF
  for DEV in "${ADJUSTMENT_DEVS[@]}"; do
    echo "      - \"$DEV\"" >> "$ADJUSTMENT_FILE"
  done
fi

if [ -n "$ADJUSTMENT_VOLS" ]; then
  cat <<EOF >> "$ADJUSTMENT_FILE"
    volumes:
EOF
  for VOL in "${ADJUSTMENT_VOLS[@]}"; do
    echo "      - \"$VOL\"" >> "$ADJUSTMENT_FILE"
  done
fi

if [ -n "$ADJUSTMENT_ENVS" ]; then
  cat <<EOF >> "$ADJUSTMENT_FILE"
    environment:
EOF
  for ENV in "${ADJUSTMENT_ENVS[@]}"; do
    echo "      $ENV" >> "$ADJUSTMENT_FILE"
  done
fi

if [ -n "$ADJUSTMENT_CAPS" ]; then
  cat <<EOF >> "$ADJUSTMENT_FILE"
    cap_add:
EOF
  for CAP in "${ADJUSTMENT_CAPS[@]}"; do
    echo "      - \"$CAP\"" >> "$ADJUSTMENT_FILE"
  done
fi

CRUNVER="$(crun --version | awk '/crun version /{print $3}')"
if ! sort -C -V <<< $'1.9.1\n'"$CRUNVER"; then
    OVERRIDE_ALLOW_READ=yes
EOF
fi

if [ "$OVERRIDE_ALLOW_READ" == "yes" ]; then
    cat <<EOF >> "$ADJUSTMENT_FILE"
    read_only: false
EOF
fi

if [ "$CDC_DEBUG" -ge "2" ]; then
  echo "==== ADJUSTMENT FILE ===="
  cat "$ADJUSTMENT_FILE"
  echo "======================="
fi

#PRELAUNCHER=""
#TRAY="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".tray" <<< "$PODMAN_CONFIG")"
#if [ -n "$TRAY" -a "$TRAY" != "null" ]; then
#    TRAY_ICON="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".tray.icon" <<< "$PODMAN_CONFIG")"
#    TRAY_NAME="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".tray.name" <<< "$PODMAN_CONFIG")"
#    TRAY_WMCLASS="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".tray.\"wmclass\"" <<< "$PODMAN_CONFIG")"
#    TRAY_WMCLASS_ARG=""
#    if [ "$TRAY_WMCLASS" == "null" ]; then
#        TRAY_WMCLASS_FILE="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".tray.\"wmclass-file\"" <<< "$PODMAN_CONFIG")"
#        if [ "$TRAY_WMCLASS_FILE" != "null" ]; then
#            TRAY_WMCLASS="$(cat "home/$TRAY_WMCLASS_FILE")"
#            TRAY_WMCLASS_ARG="--wm-class $TRAY_WMCLASS"
#        fi
#    else
#      TRAY_WMCLASS_ARG="--wm-class $TRAY_WMCLASS"
#    fi
#    PRELAUNCHER="\"${TOOLPATH}/../dependencies/submodules/tray-utils/bin/tray-wrapper\" --app-name \"$TRAY_NAME\" --icon \"home/$TRAY_ICON\" $TRAY_WMCLASS_ARG --"
#else
#    PRELAUNCHER=""
#fi

if [ "$CDC_DEBUG" -ge "3" ]; then
    echo "=== CONFIG ==="
    podman-compose -f compose.yaml -f "$ADJUSTMENT_FILE" "${CONFIG_FILE[@]}" config
    echo "=============="
fi

# Handle changes between versions of podman in how to not create a pod
# (we need "--userns", which cannot be used in pods)
PODMAN_VERSION=$(podman-compose version --short 2>/dev/null)
#VERSION=$(podman-compose --version | awk '/podman-compose/{print $NF}')
if sort -CV <<< "1.2.0"$'\n'"$PODMAN_VERSION"; then
    PODMAN_COMPOSE_UP_ARGS+=("--in-pod" "false")
    PODMAN_COMPOSE_EXEC_ARGS+=("--in-pod" "false")
fi

if [ -n "${PODMAN_UP_ARGS[0]}" ]; then
    # This mangling seems to get the escaping right enough
    ARGS=${PODMAN_UP_ARGS[@]}
    PODMAN_COMPOSE_UP_ARGS+=("--podman-run-args" "\\$ARGS")
fi

if [ -n "${PODMAN_EXEC_ARGS[0]}" ]; then
    # This mangling seems to get the escaping right enough
    ARGS=${PODMAN_EXEC_ARGS[@]}
    PODMAN_COMPOSE_EXEC_ARGS+=("--podman-run-args" "\\$ARGS")
fi

# Run auto-update if we are supposed to do that before launching
AUTO_UPDATE="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".\"auto-update\"" <<< "$PODMAN_CONFIG")"
if [ -z "$CDC_NO_RECURSE" -a -n "$AUTO_UPDATE" -a "$AUTO_UPDATE" != "null" -a "$LAUNCHER" != "update-check" -a "$LAUNCHER" != "download" -a "$LAUNCHER" != "update" ]; then
    CDC_NO_RECURSE=1 "${SCRIPTPATH}/cdc-update-if-needed"
fi

# If the service is already running, get its CONTAINER_ID
if sort -CV <<< "1.0.7"$'\n'"$PODMAN_VERSION"; then
    # podman-compose 1.0.7 and forward has a 'stats' action that allows finding the CONTAINER_ID directly
    CONTAINER_ID="$(podman-compose -p "${APP}" stats "${SERVICE}" --no-reset --no-stream --format '{{.ID}}' 2>/dev/null)"
else
    # First extract or guess podman-config:s container name
    CONTAINER_NAME="$(echo "$PODMAN_CONFIG" | yq -r ".services[\"$SERVICE\"].container_name // \"${APP}_${SERVICE}_1\"")"
    # Then use podman directly to find the CONTAINER_ID
    CONTAINER_ID="$(podman inspect --format '{{.Id}}' "$CONTAINER_NAME" 2>/dev/null || true)"
fi
if [ -n "$CONTAINER_ID" ]; then
    if [ "$(podman inspect -f '{{.State.Status}}' "$CONTAINER_ID")" != "running" ]; then
	podman rm "$CONTAINER_ID"
	CONTAINER_ID=""
    fi
fi

if [ -z "$CONTAINER_ID" -a -n "$SERVICE" ]; then
    if [ -n "$DBUS_PROXY" ]; then
	echo "Launching:" "$DBUS_SESSION_BUS_ADDRESS" "$XDG_RUNTIME_DIR/bus-proxy-$APP-$LAUNCHER" "${DBUS_PROXY_ARGS[@]}"
	# Workaround: sometimes xdb-dbus-proxy fails and leaves an empty directory behind, which stops further attmepts with "address in use"
	if [ -d "$XDG_RUNTIME_DIR/bus-proxy-$APP-$LAUNCHER" ]; then
	    rmdir "$XDG_RUNTIME_DIR/bus-proxy-$APP-$LAUNCHER"
	fi
	xdg-dbus-proxy "$DBUS_SESSION_BUS_ADDRESS" "$XDG_RUNTIME_DIR/bus-proxy-$APP-$LAUNCHER" "${DBUS_PROXY_ARGS[@]}" &
	DBUS_PROXY_PID=$?
	trap "kill $DBUS_PROXY_PID" EXIT
    fi

    if [ -n "$DBUS_SYSTEM_PROXY" ]; then
	echo "Launching:" xdg-dbus-proxy "$DBUS_SYSTEM_BUS_ADDRESS" "$XDG_RUNTIME_DIR/system-bus-proxy-$APP-$LAUNCHER" "${DBUS_SYSTEM_PROXY_ARGS[@]}"
	# Workaround: sometimes xdb-dbus-proxy fails and leaves an empty directory behind, which stops further attmepts with "address in use"
	if [ -d "$XDG_RUNTIME_DIR/system-bus-proxy-$APP-$LAUNCHER" ]; then
	    rmdir "$XDG_RUNTIME_DIR/system-bus-proxy-$APP-$LAUNCHER"
	fi
	xdg-dbus-proxy "$DBUS_SYSTEM_BUS_ADDRESS" "$XDG_RUNTIME_DIR/system-bus-proxy-$APP-$LAUNCHER" "${DBUS_SYSTEM_PROXY_ARGS[@]}" &
	DBUS_SYSTEM_PROXY_PID=$?
	trap "kill $DBUS_SYSTEM_PROXY_PID" EXIT
    fi
    trap 'podman-compose -p "${APP}" --env-file "${CDC_APP_PATH}/.env" -f compose.yaml -f "${ADJUSTMENT_FILE}" "${CONFIG_FILE[@]}" "${PODMAN_COMPOSE_UP_ARGS[@]}" down "${SERVICE}" > /dev/null; rm -f "$ADJUSTMENT_FILE"' exit
    if [ "$CDC_DEBUG" -ge "1" ]; then
	echo podman-compose -p "${APP}" --env-file "${CDC_APP_PATH}/.env" -f compose.yaml -f "${ADJUSTMENT_FILE}" "${CONFIG_FILE[@]}" "${PODMAN_COMPOSE_UP_ARGS[@]}" up -d "${SERVICE}"
    fi
    CONTAINER_ID=$(podman-compose -p "${APP}" --env-file "${CDC_APP_PATH}/.env" -f compose.yaml -f "${ADJUSTMENT_FILE}" "${CONFIG_FILE[@]}" "${PODMAN_COMPOSE_UP_ARGS[@]}" up -d "${SERVICE}")
    podman-compose -p "${APP}" --env-file "${CDC_APP_PATH}/.env" -f compose.yaml -f "${ADJUSTMENT_FILE}" "${CONFIG_FILE[@]}" "${PODMAN_COMPOSE_UP_ARGS[@]}" logs "${SERVICE}"
else
    echo "Note: service already running with CONTAINER_ID: $CONTAINER_ID"
fi

if [ "$CDC_DEBUG" -ge "1" ]; then
    echo ${PRELAUNCHER} podman-compose -p "$APP" --env-file "${CDC_APP_PATH}/.env" -f compose.yaml -f "${ADJUSTMENT_FILE}" "${CONFIG_FILE[@]}" "${PODMAN_COMPOSE_EXEC_ARGS[@]}" exec "${PODMAN_COMPOSE_EXEC_POST_ARGS[@]}" --user "${USER}" "${SERVICE}" bash -c "${LAUNCH_SCRIPT}" bash "$@"
fi

if [ "$TYPE" == "tray" ]; then

    MULTI_TRAY_ARGS=""
    ICON="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".tray.icon" <<< "$PODMAN_CONFIG")"
    ENTRY_NBR="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".tray.entries | length" <<< "$PODMAN_CONFIG")"
    for (( ENTRY_IDX=0; ENTRY_IDX<ENTRY_NBR; ENTRY_IDX++ )); do
	ENTRY_NAME="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".tray.entries[$ENTRY_IDX].name" <<< "$PODMAN_CONFIG")"
	ENTRY_WMCLASS="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".tray.entries[$ENTRY_IDX].wmclass" <<< "$PODMAN_CONFIG")"
	if [ "$ENTRY_WMCLASS" = "null" ]; then
	    ENTRY_WMCLASS_FILE="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".tray.entries[$ENTRY_IDX].\"wmclass-file\"" <<< "$PODMAN_CONFIG")"
	    if [ "$ENTRY_WMCLASS_FILE" != "null" ]; then
		ENTRY_WMCLASS=$(cat "home/$ENTRY_WMCLASS_FILE")
	    fi
	fi
	ENTRY_LAUNCH="$(yq -r ".\"x-launchers\".\"$LAUNCHER\".tray.entries[$ENTRY_IDX].launch" <<< "$PODMAN_CONFIG")"
	MULTI_TRAY_ARGS="$MULTI_TRAY_ARGS --app \"$ENTRY_NAME\" \"$ENTRY_WMCLASS\" \"./$ENTRY_LAUNCH\""
    done

    /usr/bin/env --split-string="\"$TOOLPATH/../dependencies/submodules/tray-utils/bin/multi-app-tray\" --icon \"$ICON\" $MULTI_TRAY_ARGS"

elif [ "$TYPE" != "background" ]; then

    ${PRELAUNCHER} podman-compose -p "$APP" --env-file "${CDC_APP_PATH}/.env" -f compose.yaml -f "${ADJUSTMENT_FILE}" "${CONFIG_FILE[@]}" "${PODMAN_COMPOSE_EXEC_ARGS[@]}" exec "${PODMAN_COMPOSE_EXEC_POST_ARGS[@]}" --user "${USER}" "${SERVICE}" bash -c "${LAUNCH_SCRIPT}" bash "$@"

else

    ${PRELAUNCHER} podman-compose -p "$APP" --env-file "${CDC_APP_PATH}/.env" -f compose.yaml -f "${ADJUSTMENT_FILE}" "${CONFIG_FILE[@]}" "${PODMAN_COMPOSE_EXEC_ARGS[@]}" exec "${PODMAN_COMPOSE_EXEC_POST_ARGS[@]}" --user "${USER}" "${SERVICE}" bash -c "${LAUNCH_SCRIPT}" bash "$@" </dev/null

fi
