version: "3.8"

x-application:

  readme: |
    python-develop: bare-bones console with access to host network
    for Python development.

  override-default: |
    version: "3.8"

  env-default: |
    # No configurable options


services:

  ## COMMON PART ##

  common: &common

    image: "cdc-u24"

    #entrypoint: ["bash", "-c", "trap 'exit 0' TERM; bash -c \"$$(printf \"%s\\n\" \"$@\")\"; while true; do sleep 1; done", "--"]
    entrypoint: ["/bin/tini", "/bin/bash", "--", "-c", "$$(printf \"%s\\n\" \"$@\"); sleep infinity"]

    network: none

    working_dir: /home/${USER}
    user: "${USER}"

    environment: &common-env
      LANG: "${LANG}"
      XDG_RUNTIME_DIR: "/tmp/${USER}/run"
      XDG_CURRENT_DESKTOP: "${XDG_CURRENT_DESKTOP}"
      DESKTOP_SESSION: "${DESKTOP_SESSION}"

    cap_drop:
      - ALL

    security_opt:
      - no-new-privileges

    read_only: true
    tmpfs:
      - /tmp
      - /run

    shm_size: "1G"

    volumes: &common-volumes
      - "${CDC_APP_PATH}/home:/home/${USER}:rw"

    devices:
      - "/dev/dri:/dev/dri"

    security_opt:
      - no-new-privileges

    userns_mode: "keep-id"

  ## DOWNLOAD ##

  download:
    <<: *common

    network_mode: bridge

    x-launchers:
      download:
        script: &download_script
          - echo "DOWNLOAD"
          - mkdir -p Downloads
          - VERSION="$$(curl -s https://api.github.com/repos/ollama/ollama/releases/latest | jq --raw-output '.name')"
          - LATESTURL="$$(curl -s https://api.github.com/repos/ollama/ollama/releases/latest | jq --raw-output '.assets[] | .browser_download_url' | grep ollama-linux-amd64.tgz)"
          - LATESTFILENAME="ollama-linux-amd64-$$VERSION.tgz"
          - |
            if [ ! -e "Downloads/$$LATESTFILENAME" ]; then
              curl -L -o "Downloads/$$LATESTFILENAME" "$$LATESTURL"
            fi
          - ln -sf "$$LATESTFILENAME" Downloads/ollama-linux-amd64-latest.tgz

      redownload:
        script: &redownload_script
          - echo "REDOWNLOAD"
          - mkdir -p Downloads
          - VERSION="$$(curl -s https://api.github.com/repos/ollama/ollama/releases/latest | jq --raw-output '.name')"
          - LATESTURL="$$(curl -s https://api.github.com/repos/ollama/ollama/releases/latest | jq --raw-output '.assets[] | .browser_download_url' | grep ollama-linux-amd64.tgz)"
          - LATESTFILENAME="ollama-linux-amd64-$$VERSION.tgz"
          - rm -rf "Downloads/$$LATESTFILENAME" Downloads/ollama-linux-amd64-latest.tgz
          - *download_script

  ## INSTALL ##

  install:
    <<: *common

    x-launchers:
      install:
        script: &install_script
          - VERSION="$${1:-ollama-linux-amd64-latest.tgz}";
          - echo "INSTALL $$VERSION";
          - |
            if [ ! -e ~/.local/share/ollama ]; then
              mkdir -p ~/.local/share/ollama
              cd ~/.local/share/ollama
              tar -zxf ~/Downloads/"$$VERSION"
            fi

      reinstall:
        script: &reinstall_script
          - VERSION="$${1:-ollama-linux-amd64-latest.tgz}"
          - echo "REINSTALL $$VERSION"
          - rm -rf ~/.local/share/ollama
          - *install_script

  ## UPDATE ##

  update:
    <<: *common

    network_mode: bridge

    x-launchers:
      update-check:
        script:
          - echo "UPDATE CHECK"
          - VERSION="$$(curl -s https://api.github.com/repos/ollama/ollama/releases/latest | jq --raw-output)"
          - LATESTFILENAME="ollama-linux-amd64-$$VERSION.tgz"
          - mkdir -p Downloads
          - if [ -e "Downloads/$$LATESTFILENAME" ]; then
              echo "No new version";
              exit 0;
            fi
          - echo "File missing, or server-side file newer"
          - exit 1

      update:
        script:
          - echo "UPDATE"
          - *redownload_script
          - *reinstall_script

  ## EXECUTE ###

  ollama:
    <<: *common

    network_mode: bridge

    ports:
      - "11434:11434"

    x-launchers:
      ollama-serve:
        script:
          - echo "ollama-serve"
          - OLLAMA_HOST=0.0.0.0:11434 ~/.local/share/ollama/bin/ollama serve
        features:
          - GPU

      ollama:
        script:
          - echo "ollama"
          - ~/.local/share/ollama/bin/ollama "$@"

      interactive:
        interactive: true

        script:
          - echo "INTERACTIVE"
          - bash
